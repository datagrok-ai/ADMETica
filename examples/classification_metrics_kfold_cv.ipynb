{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2188495-3152-4fe2-b5f2-161d8d3f799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the dataset name (e.g., 'CYP1A2-Substrate'):  cyp1a2-inhibitor\n",
      "Please enter column with structures:  smiles\n",
      "Please enter target column:  Activity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found at: /Users/aleksashka/admetica/metabolism/cyp1a2-inhibitor/cyp1a2-inhibitor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                    | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing      | 227 K  | train\n",
      "1 | agg             | MeanAggregation         | 0      | train\n",
      "2 | bn              | BatchNorm1d             | 600    | train\n",
      "3 | predictor       | BinaryClassificationFFN | 90.6 K | train\n",
      "4 | X_d_transform   | Identity                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "318 K     Trainable params\n",
      "0         Non-trainable params\n",
      "318 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5ebb6ef693467e8683e9e4bf863f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571c353b4b85433091a7800225182a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                    | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing      | 227 K  | train\n",
      "1 | agg             | MeanAggregation         | 0      | train\n",
      "2 | bn              | BatchNorm1d             | 600    | train\n",
      "3 | predictor       | BinaryClassificationFFN | 90.6 K | train\n",
      "4 | X_d_transform   | Identity                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "318 K     Trainable params\n",
      "0         Non-trainable params\n",
      "318 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b870d19b89498395758a1110e052e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cf7da5e37243fb95719e24cce21399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                    | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing      | 227 K  | train\n",
      "1 | agg             | MeanAggregation         | 0      | train\n",
      "2 | bn              | BatchNorm1d             | 600    | train\n",
      "3 | predictor       | BinaryClassificationFFN | 90.6 K | train\n",
      "4 | X_d_transform   | Identity                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "318 K     Trainable params\n",
      "0         Non-trainable params\n",
      "318 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9905655a1a4687a5b1391bf0f6def5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from lightning import pytorch as pl\n",
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "def find_dataset_path(dataset_name):\n",
    "    current_directory = os.getcwd()\n",
    "    base_directory = os.path.abspath(os.path.join(current_directory, \"..\"))\n",
    "    \n",
    "    dataset_pattern = os.path.join(base_directory, \"**\", f\"{dataset_name}.csv\")\n",
    "    matches = glob.glob(dataset_pattern, recursive=True)\n",
    "    \n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "dataset_name = input(\"Please enter the dataset name (e.g., 'CYP1A2-Substrate'): \")\n",
    "smiles_column = input(\"Please enter column with structures: \")\n",
    "target_column = input(\"Please enter target column: \")\n",
    "targets_column = [target_column]\n",
    "\n",
    "input_path = find_dataset_path(dataset_name)\n",
    "\n",
    "if input_path is None:\n",
    "    print(f\"Dataset '{dataset_name}' not found.\")\n",
    "else:\n",
    "    print(f\"Dataset found at: {input_path}\")\n",
    "\n",
    "    num_folds = 10\n",
    "    num_workers = 0\n",
    "\n",
    "    df_input = pd.read_csv(input_path)\n",
    "    mean = df_input[target_column].mean()\n",
    "\n",
    "    smis = df_input[smiles_column].values\n",
    "    ys = df_input[targets_column].values\n",
    "\n",
    "    all_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis, ys)]\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for train_index, test_index in kf.split(all_data):\n",
    "        train_data = [all_data[i] for i in train_index]\n",
    "        test_data = [all_data[i] for i in test_index]\n",
    "\n",
    "        featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "        train_dset = data.MoleculeDataset(train_data, featurizer)\n",
    "        test_dset = data.MoleculeDataset(test_data, featurizer)\n",
    "\n",
    "        train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "        test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "        mp = nn.BondMessagePassing()\n",
    "        agg = nn.MeanAggregation()\n",
    "        ffn = nn.BinaryClassificationFFN()\n",
    "\n",
    "        mpnn = models.MPNN(mp, agg, ffn, batch_norm=True)\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=True,\n",
    "            enable_checkpointing=True,\n",
    "            enable_progress_bar=True,\n",
    "            accelerator=\"cpu\",\n",
    "            devices=1,\n",
    "            max_epochs=50,\n",
    "        )\n",
    "\n",
    "        trainer.fit(mpnn, train_loader)\n",
    "\n",
    "        predictions = trainer.predict(mpnn, test_loader)\n",
    "        predictions = np.concatenate(predictions)\n",
    "        true_labels = ys[test_index]\n",
    "\n",
    "        preds_binary = (predictions > mean).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(true_labels, preds_binary).ravel()\n",
    "\n",
    "        metrics.append({\n",
    "            'TP': tp,\n",
    "            'TN': tn,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'Sensitivity': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "            'Specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "            'Accuracy': accuracy_score(true_labels, preds_binary),\n",
    "            'Balanced Accuracy': balanced_accuracy_score(true_labels, preds_binary),\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "    average_metrics = metrics_df.mean().to_frame(name='Average').T\n",
    "\n",
    "    print(average_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a264cdb-eb2b-4444-9b1d-9fcd0e51d587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
